{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LoadWalks.ipynb","provenance":[],"authorship_tag":"ABX9TyNUJ2UiAcakc2/40CCZjyy5"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ABw7_W9eArgM","executionInfo":{"status":"ok","timestamp":1614770437800,"user_tz":360,"elapsed":499,"user":{"displayName":"Jack Bressett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj8LAu0rdLeGhHZPxw7waI-wjt06PdOC9E6bl_O=s64","userId":"08923683069860490448"}}},"source":["def read_many_hdf5():\r\n","  \r\n","  walks,counts = [],[]\r\n","  \r\n","  # Open the HDF5 file\r\n","  file = h5py.File('/content/drive/My Drive/CapstoneWalks/MetaWalks.h5', \"r+\")\r\n","  walks = np.array(file[\"/walks\"]).astype(\"uint8\")\r\n","  file.close()\r\n","\r\n","  file = h5py.File('/content/drive/My Drive/CapstoneWalks/MetaCounts.h5', \"r+\")\r\n","  counts = np.array(file[\"/counts\"]).astype(\"uint8\")\r\n","  file.close()\r\n","  return walks,counts\r\n","\r\n","\r\n","def read_one_hdf5(path):\r\n","  \r\n","  data = []\r\n","  \r\n","  # Open the HDF5 file\r\n","  file = h5py.File(path, \"r+\")\r\n","  data = np.array(file[\"default\"]).astype(\"float32\")\r\n","  file.close()\r\n","  print(\"Completed\")\r\n","  return data\r\n","\r\n","def writeSingleDataset(arr,path):\r\n","\r\n","  with h5py.File(path, 'w') as f:\r\n","    dset = f.create_dataset(\"default\", (arr.shape[0],arr.shape[1],arr.shape[2]))\r\n","    dset[0:arr.shape[0]] = arr\r\n","    f.close()\r\n","  return print(\"completed\")\r\n","\r\n","\r\n","def process_loaded_data(img_rows, img_cols, in_channel):\r\n","  #Read images from files\r\n","  walk_imgs,count_imgs = read_many_hdf5()\r\n","  targets = pd.read_csv('/content/drive/My Drive/CapstoneWalks/MetaTargets.csv')\r\n","  #Convert data type and scale \r\n","  walk_imgs,count_imgs = np.asarray(walk_imgs, dtype=np.float32),np.asarray(count_imgs, dtype=np.float32)\r\n","  walk_imgs,count_imgs = walk_imgs/255,count_imgs/steps\r\n","\r\n","  # reshape to match Keras expectaions\r\n","  walk_imgs = walk_imgs.reshape(walk_imgs.shape[0], img_rows, img_cols, in_channel)\r\n","  count_imgs = count_imgs.reshape(count_imgs.shape[0], img_rows, img_cols, in_channel)\r\n","\r\n","  #We want to pair the images together, we have a dimension of 4\r\n","  x_train_Stack = np.stack((walk_imgs,count_imgs), axis=4)\r\n","\r\n","\r\n","  x_train, x_test, y_train, y_test = train_test_split(x_train_Stack, targets, test_size = 10000, random_state=42)\r\n","\r\n","\r\n","  x_train_Walks = np.asarray(x_train[:,:,:,:,0])\r\n","  x_test_Walks = np.asarray(x_test[:,:,:,:,0])\r\n","\r\n","\r\n","  x_train_Counts = np.asarray(x_train[:,:,:,:,1])\r\n","  x_test_Counts = np.asarray(x_test[:,:,:,:,1])\r\n","\r\n","  return x_train_Walks, x_test_Walks, x_train_Counts, x_test_Counts, y_train, y_test\r\n","\r\n","def store_many_hdf5(data1, data2, path):\r\n","  \"\"\" Stores an array of images to HDF5.\r\n","  Parameters:\r\n","  ---------------\r\n","  walks       images array, (N, 100, 100, 3) to be stored\r\n","  counts      images array, (N, 100, 100, 3) to be stored\r\n","  \"\"\"\r\n","  # Create a new HDF5 file\r\n","  file = h5py.File(path, \"w\")\r\n","  # Create a dataset in the file\r\n","  data1 = file.create_dataset(\"data1\", np.shape(data1), h5py.h5t.STD_U8BE, data=data1,)\r\n","  file.close()\r\n","  \r\n","  # Create a new HDF5 file\r\n","  file = h5py.File(path, \"a\")\r\n","  # Create a dataset in the file\r\n","  data2 = file.create_dataset(\"data2\", np.shape(data2), h5py.h5t.STD_U8BE, data=data2)\r\n","  file.close()\r\n","  \r\n","  return print(\"Completed\")\r\n","\r\n","def CombineProcessedData(arr,arr2,path,y_true):\r\n","  if y_true == 1:\r\n","    with h5py.File(path, 'w') as f:\r\n","      dset = f.create_dataset(\"default\", (2*arr.shape[0],arr.shape[1]))\r\n","      dset[0:arr.shape[0]] = arr\r\n","      print(\"Halfway\")\r\n","      dset[arr.shape[0]:(2*arr.shape[0])] = arr2\r\n","      f.close()\r\n","    return print(\"completed\")\r\n","  \r\n","  with h5py.File(path, 'w') as f:\r\n","    dset = f.create_dataset(\"default\", (2*arr.shape[0],arr.shape[1],arr.shape[2]))\r\n","    dset[0:arr.shape[0]] = arr\r\n","    print(\"Halfway\")\r\n","    dset[arr.shape[0]:(2*arr.shape[0])] = arr2\r\n","    f.close()\r\n","    return print(\"completed\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ADRfhZCdF9MJ"},"source":[""],"execution_count":null,"outputs":[]}]}